= spring-boot-kafka
:pdf-themesdir: ../themes
:pdf-fontsdir: ../fonts
:pdf-theme: KaiGenGothicCN


== 名词解释

. AR Assigned Replicas 分区中所有的副本统称为 AR

. ISR(IN SYNC REPLICAS) 所有的与 Leader 部分保持一定程度的副本组成了 ISR(包括了 leader 副本在内).

. OSR(OUT OF SYNC REPLICAS) 与 Leader 副本滞后过多的副本

. HW(High Watermark) 高水位, 标识了一个特定的 offset, 消费者只能拉取到这个 offset 之前的消息.

. LEO(LOG END OFFSET) 即日志末尾唯, 记录了该副本地城日志(log)中下一条消息的位置值.注意是下一条消息,也就是说,如果 LEO=10,那么表示该副本保存了 10 条消息,位置值范围是[0,9].

== kafka 生产消息的过程

== 分区器

kafka 默认分区器根据消息的 key 来进行分区的分配, 即 hash(key)% numPartitions.如果 Key 相同,那么就会分配到统一的分区.
org.apache.kafka.clients.producer.internals.DefaultPartitioner

== 拦截器

Producer 拦截器(interceptor)是个相当新的功能, 它和 consumer端的 interceptor 是在 kafka 0.10 版本被引入的名主要用于实现 clients 端的定制化控制逻辑.
生产者拦截器可以用在消息发送前做一些准备工作,

使用场景:
1.按照某个规则过滤不符合要求的消息; 2.修改消息的内容; 3.统计类的需求.

org.apache.kafka.clients.producer.ProducerInterceptor

== 生产者的参数

=== acks

这个参数用来指定分区中必须有多少个副本收到这条消息,之后生产者才会认为这条消息时写入是成功的.
acks 是消息可靠性和吞吐量之间的权衡.

. acks=0,生产者在成功写入消息之前不会等待任何来自服务器的响应.如果出现问题,生产者是感知不到的,消费就丢失了.
不过因为生产者不用等待服务器的响应,所以它可以以网络能够支持的最大速度发送消息,从而达到很高的吞吐量.

. ack=1,默认值就是 1,只要集群的 leader 节点收到消息,生产这就会收到一个来自服务器的响应,如果消息无法到达 leader 节点,生产者会收到一个错误的响应, 为了避免数据丢失,生产者会重发消息.这样还是可能会丢失数据,如果收到写成功的通知,此时 leader 节点还没来得及同步数据到 follower 节点,leader 节点崩溃,就会导致数据丢失.

. ack=-1,只有当所有参与复制的节点都收到消息时,生产者会收到一个来自服务器的成功响应,这种模式是最安全的,它可以保证不止一个服务器收到消息.

注意: acks参数配置是一个字符串类型,不是整数类型,

=== retries

生产者从服务器收到的错误有可能是临时的错误(比如分区找不到 leader).这种情况下,如果达到了 retries 设置的次数,生产者会放弃重试并返回错误, 默认情况下,生产者会在每次重试之间等待 100ms , 可以通过 retry.backoff.ms 参数来修改这个时间间隔.

=== batch size

当有多个消息要发送到同一个分区时,生产者会把他们放在同一个批次里.该参数指定了一次批次可以使用的内存大小,按照字节数极端,而不是消息的个数.
当批次被填满,批次里所有的消息都会被发送出去.不过生产者并不一定都会等到被填满才大宋,半慢的批次,甚至只包含一个消息的批次也可能被发送.
所以就算把 batch.size 设置的很大, 也不会造成延迟,只会占用更对的内存,如果设置的太小,生产者会因为频繁发送消息而增加一些额外的开销.

=== 异步提交

手动提交有个缺点,那就是当放弃提交调用时应用汇阻塞.当然我们可以减少手动提交的频率,但这个会增加消息重复的概率(和自动提交一样).另外一个解决方法是,使用异步提交的 API. +
但是异步提交也有缺点,那就是如果服务器返回提交失败,异步提交并不会进行重试.相比较起来,同步提交会镜像重试直到成功或者最后抛出异常给应用. +
异步提交没有实现重试,如果存在多个异步提交,进行充实可能会导致位移覆盖.举个例子,加入我们发起一个异步提交 commit A, 此时提交位移为 2000,随后又发起了一个异步提交 3000, commit A 提交是被但是 commitB 提交成功,此时 commitA 进行重试并成功的话,会将实际上将已经提交的位移从 3000 回滚到 2000,导致消息重复消费.

== 消费者参数

=== fetch.min.bytes

这个参数允许消费者指定从 broker 读取消息时最小的数据量.当消费者从 broker 读取消息时,如果数据量小于这个阈值,broker 会等待直到有足够的数据,然后才返回给消费者.
对于写入量不是高的主题了来说,这个参数可以减少 broker 和 消费者的压力,因为减少了往返的时间,而对于有大量消费者的主题来说,则可以明显减轻 broker 压力.

=== fetch.max.wait.ms

上面的 fetch.min.bytes 参数指定了消费者最小的数据量,而这个参数则指定了消费者读取时最长等待时间,从而避免了长时间的阻塞.这个参数默认为 500ms.

=== max.partition.fetch.bytes

这个参数指定了每个分区返回的最多字节数,默认为 1M.也就是说,KafkaConsumer.poll() 返回记录列表时,每个分区的记录字节数最多为 1M.
如果一个主题有 20 个分区,同时有 5 个消费者,那么每个消费者需要返回 4M 的空间来处理消息.实际情况下,我们需要设置更多的空间,这样当消费者宕机时,其他消费者可以承担更多的分区.

=== max.poll.records

这个参数控制一个 poll() 调用返回的记录数,这个可以控制应用在拉取循环中的处理数据量.0


除了消息顺序追加,页缓存等技术,kafka 技术还使用了零拷贝技术来进一步提升性能.
"零拷贝技术"只用将磁盘文件的数据复制到页面缓存中一次,然后将数据从页面缓存直接发送到网络中(发送给不同的订阅者时,都可以使用相同讴歌页面缓存), 避免了重复复制操作.如果有 10 个消费者,传统方式下,数据复制次数为 4*10=40 次,而使用"零拷贝技术"只需要拷贝 1+10=11 次,一次为从磁盘复制到页面缓存,10 次表示 10 个消费者各自读取一次页面缓存.

== 稳定性

kafka 的消息传输保障机制非常直观.当 producer 向 broker 发送消息时,一旦这条消息被 commit ,由于副本机制(replication)的存在,它就不会丢失.
但是如果 producer 发送数据给 broker 后,遇到的网络问题而造成通信中断,那么 producer 就无法判断该条消息是否已经提交了(commit).虽然 kafka] 无法确定网络故障期间发送了什么.
但是 producer 可以 retry 多次,确保消息已经正确传输到 broker 中,所以目前 kafka 实现的是 at least once.

=== 幂等性

所谓的幂等性,就是对接口的多次调用所残生的结果接调用一次是一致的.生产者在进行重试的时候可能会重复写入消息,二 使用kafka 的幂等性功能就可以避免这种情况.

幂等性条件:
只能保证 producer 在单个回话内不丢不重,如果 producer 出现意外挂掉在重启是无法保证的(幂等性情况下,是无法获取之前的状态信息,因此是无法做到跨会话级别的不丢不重); 只能保证单个分区内的幂等性,不能跨多个分区的幂等性.





















